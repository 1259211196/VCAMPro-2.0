#import <Foundation/Foundation.h>
#import <UIKit/UIKit.h>
#import <AVFoundation/AVFoundation.h>
#import <VideoToolbox/VideoToolbox.h>
#import <objc/runtime.h>
#import <objc/message.h>

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wunguarded-availability-new"
#pragma clang diagnostic ignored "-Wdeprecated-declarations"

// ============================================================================
// ã€1. æ— ç—•è½¬ç å¼•æ“ (ä¼ªè£…æˆç³»ç»Ÿç¼“å­˜æ–‡ä»¶)ã€‘
// ============================================================================
@interface VCAMStealthPreprocessor : NSObject
+ (void)processVideoAtURL:(NSURL *)sourceURL completion:(void(^)(BOOL success))completion;
@end

@implementation VCAMStealthPreprocessor
+ (void)processVideoAtURL:(NSURL *)sourceURL completion:(void(^)(BOOL success))completion {
    // ä¼ªè£…æ–‡ä»¶åï¼Œå­˜æ”¾åœ¨ tmp ç›®å½•ï¼Œçœ‹èµ·æ¥åƒæ™®é€šçš„ç³»ç»Ÿå¤šåª’ä½“ç¼“å­˜ï¼Œé˜²æ­¢æ²™ç›’æ‰«æ
    NSString *destPath = [NSTemporaryDirectory() stringByAppendingPathComponent:@"com.apple.avfoundation.videocache.tmp"];
    [[NSFileManager defaultManager] removeItemAtPath:destPath error:nil];
    
    AVAsset *asset = [AVAsset assetWithURL:sourceURL];
    AVAssetExportSession *exportSession = [[AVAssetExportSession alloc] initWithAsset:asset presetName:AVAssetExportPresetHighestQuality];
    exportSession.outputURL = [NSURL fileURLWithPath:destPath];
    exportSession.outputFileType = AVFileTypeMPEG4;
    exportSession.shouldOptimizeForNetworkUse = YES;

    [exportSession exportAsynchronouslyWithCompletionHandler:^{
        dispatch_async(dispatch_get_main_queue(), ^{
            if (exportSession.status == AVAssetExportSessionStatusCompleted) {
                if (completion) completion(YES);
            } else {
                if (completion) completion(NO);
            }
        });
    }];
}
@end

// ============================================================================
// ã€2. å¯„ç”Ÿçº§æ¸²æŸ“å¼•æ“ (é›¶æ‹·è´ã€é›¶å…ƒæ•°æ®ç ´å)ã€‘
// ============================================================================
@interface VCAMParasiteCore : NSObject
@property (nonatomic, strong) AVAssetReader *assetReader;
@property (nonatomic, strong) AVAssetReaderOutput *trackOutput;
@property (nonatomic, assign) VTPixelTransferSessionRef transferSession;
@property (nonatomic, strong) NSLock *readLock;
@property (nonatomic, assign) CVPixelBufferRef lastPixelBuffer;
@property (nonatomic, assign) BOOL isEnabled;
+ (instancetype)sharedCore;
- (void)loadVideo;
- (void)parasiteInjectSampleBuffer:(CMSampleBufferRef)sampleBuffer;
@end

@implementation VCAMParasiteCore
+ (instancetype)sharedCore {
    static VCAMParasiteCore *core = nil;
    static dispatch_once_t onceToken;
    dispatch_once(&onceToken, ^{
        core = [[VCAMParasiteCore alloc] init];
    });
    return core;
}

- (instancetype)init {
    if (self = [super init]) {
        _readLock = [[NSLock alloc] init];
        _lastPixelBuffer = NULL;
        _isEnabled = YES; 
        
        // å»ºç«‹åº•å±‚ GPU é«˜é€Ÿä¼ è¾“é€šé“
        VTPixelTransferSessionCreate(kCFAllocatorDefault, &_transferSession);
        if (_transferSession) {
            // ç¡®ä¿ç”»é¢å®Œç¾å¡«å……ï¼Œæ— é»‘è¾¹ï¼Œä¸å¼•èµ·è§†è§‰é£æ§æ€€ç–‘
            VTSessionSetProperty(_transferSession, kVTPixelTransferPropertyKey_ScalingMode, kVTScalingMode_CropSourceToCleanAperture);
        }
        [self loadVideo];
    }
    return self;
}

- (void)loadVideo {
    [self.readLock lock];
    if (self.assetReader) { [self.assetReader cancelReading]; self.assetReader = nil; self.trackOutput = nil; }
    
    NSString *videoPath = [NSTemporaryDirectory() stringByAppendingPathComponent:@"com.apple.avfoundation.videocache.tmp"];
    if (![[NSFileManager defaultManager] fileExistsAtPath:videoPath]) {
        [self.readLock unlock];
        return;
    }
    
    AVAsset *asset = [AVAsset assetWithURL:[NSURL fileURLWithPath:videoPath]];
    self.assetReader = [AVAssetReader assetReaderWithAsset:asset error:nil];
    AVAssetTrack *videoTrack = [[asset tracksWithMediaType:AVMediaTypeVideo] firstObject];
    
    if (videoTrack && self.assetReader) {
        // å¼ºåˆ¶è¾“å‡ºä¸ç›¸æœºåº•å±‚ç›¸åŒçš„ 32BGRA æ ¼å¼ï¼Œå®Œç¾è´´åˆ
        NSDictionary *settings = @{(id)kCVPixelBufferPixelFormatTypeKey: @(kCVPixelFormatType_32BGRA)};
        self.trackOutput = [AVAssetReaderTrackOutput assetReaderTrackOutputWithTrack:videoTrack outputSettings:settings];
        if ([self.assetReader canAddOutput:self.trackOutput]) {
            [self.assetReader addOutput:self.trackOutput];
            [self.assetReader startReading];
        }
    }
    [self.readLock unlock];
}

- (CVPixelBufferRef)copyNextFrame {
    if (!self.assetReader) return NULL;
    
    if (self.assetReader.status == AVAssetReaderStatusCompleted) {
        [self loadVideo]; 
    }
    
    if (self.assetReader.status == AVAssetReaderStatusReading) {
        CMSampleBufferRef sbuf = [self.trackOutput copyNextSampleBuffer];
        if (sbuf) {
            CVPixelBufferRef pix = CMSampleBufferGetImageBuffer(sbuf);
            if (pix) CVPixelBufferRetain(pix);
            CFRelease(sbuf);
            return pix;
        } else {
            [self loadVideo];
        }
    }
    return NULL;
}

// ğŸ‘‘ æ ¸å¿ƒï¼šå¯„ç”Ÿæ³¨å…¥é€»è¾‘
- (void)parasiteInjectSampleBuffer:(CMSampleBufferRef)sampleBuffer {
    if (!self.isEnabled) return;
    
    [self.readLock lock];
    CVPixelBufferRef srcPix = [self copyNextFrame];
    [self.readLock unlock];
    
    if (srcPix) {
        if (_lastPixelBuffer) CVPixelBufferRelease(_lastPixelBuffer);
        _lastPixelBuffer = CVPixelBufferRetain(srcPix);
    } else {
        if (_lastPixelBuffer) srcPix = CVPixelBufferRetain(_lastPixelBuffer);
    }
    
    if (srcPix) {
        // è·å–åŸç”Ÿç›¸æœºå¸§çš„åŸå§‹å†…å­˜åœ°å€
        CVImageBufferRef dstPix = CMSampleBufferGetImageBuffer(sampleBuffer);
        
        // ã€é™ç»´æ‰“å‡»ç‚¹ã€‘ï¼šæˆ‘ä»¬ä¸æ–°å»º Bufferï¼Œä¸ä¿®æ”¹æ—¶é—´æˆ³ã€‚
        // ç›´æ¥åŠ¨ç”¨ GPU ç¡¬ä»¶ï¼ŒæŠŠæˆ‘ä»¬å‡†å¤‡å¥½çš„å›¾åƒåƒç´ ï¼Œç¡¬ç”Ÿç”Ÿâ€œè¦†ç›–â€åœ¨ç›¸æœºåŸç”Ÿå†…å­˜ä¸Šï¼
        // è¿™æ ·ï¼Œè‹¹æœåº•å±‚èµ‹äºˆè¿™ä¸€å¸§çš„æ‰€æœ‰ ISP å…ƒæ•°æ®ã€æ›å…‰æ•°æ®ã€æ—¶é—´æˆ³ 100% å¾—åˆ°äº†ä¿ç•™ï¼
        if (dstPix && self.transferSession) {
            VTPixelTransferSessionTransferImage(self.transferSession, srcPix, dstPix);
        }
        CVPixelBufferRelease(srcPix);
    }
}
@end

// ============================================================================
// ã€3. æåº¦ä¼ªè£…ä»£ç† (é˜²æ­¢å†…å­˜æ¢é’ˆæ‰«æ)ã€‘
// ============================================================================
@interface VCAMStealthProxy : NSProxy <AVCaptureVideoDataOutputSampleBufferDelegate>
@property (nonatomic, weak) id target;
@end

@implementation VCAMStealthProxy
+ (instancetype)proxyWithTarget:(id)target {
    VCAMStealthProxy *proxy = [VCAMStealthProxy alloc];
    proxy.target = target;
    return proxy;
}
- (NSMethodSignature *)methodSignatureForSelector:(SEL)sel { return [self.target methodSignatureForSelector:sel]; }
- (void)forwardInvocation:(NSInvocation *)invocation {
    if (self.target && [self.target respondsToSelector:invocation.selector]) {
        [invocation invokeWithTarget:self.target];
    }
}
- (BOOL)respondsToSelector:(SEL)aSelector {
    if (aSelector == @selector(captureOutput:didOutputSampleBuffer:fromConnection:)) return YES;
    return [self.target respondsToSelector:aSelector];
}

// ğŸ‘‘ æ·±åº¦ç±»ä¼ªè£…ï¼šå³ä½¿ TikTok éå†ä»£ç†çš„ç±»åï¼Œè¿”å›çš„ä¹Ÿæ˜¯åŸç”Ÿçš„ç±»åï¼
- (Class)class { return [self.target class]; }
- (Class)superclass { return [self.target superclass]; }
- (NSString *)description { return [self.target description]; }
- (NSString *)debugDescription { return [self.target debugDescription]; }
- (BOOL)isEqual:(id)object { return [self.target isEqual:object]; }
- (NSUInteger)hash { return [self.target hash]; }

- (void)captureOutput:(AVCaptureOutput *)output didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection {
    @autoreleasepool {
        // è§¦å‘å¯„ç”Ÿæ¸²æŸ“
        [[VCAMParasiteCore sharedCore] parasiteInjectSampleBuffer:sampleBuffer];
        // æ”¾è¡Œç»™åŸç”Ÿé€»è¾‘
        if ([self.target respondsToSelector:_cmd]) {
            [self.target captureOutput:output didOutputSampleBuffer:sampleBuffer fromConnection:connection];
        }
    }
}
@end

// ============================================================================
// ã€4. éšèº«æ§åˆ¶å° (æ— ç—•æ“ä½œ)ã€‘
// ============================================================================
@interface VCAMStealthUIManager : NSObject <UIImagePickerControllerDelegate, UINavigationControllerDelegate>
+ (instancetype)sharedManager;
- (void)showStealthMenuInWindow:(UIWindow *)window;
@end

@implementation VCAMStealthUIManager
+ (instancetype)sharedManager {
    static VCAMStealthUIManager *mgr = nil; static dispatch_once_t once;
    dispatch_once(&once, ^{ mgr = [[VCAMStealthUIManager alloc] init]; }); return mgr;
}

- (void)showStealthMenuInWindow:(UIWindow *)window {
    UIViewController *root = window.rootViewController;
    while (root.presentedViewController) root = root.presentedViewController;
    if (!root) return;
    
    // åŸç”Ÿ Alertï¼Œä¸æ·»åŠ ä»»ä½•ç¬¬ä¸‰æ–¹è‡ªå®šä¹‰ Viewï¼Œé¿å…è¢«æ‰«æ UI å±‚çº§
    UIAlertController *alert = [UIAlertController alertControllerWithTitle:@"ğŸ“¸ ç³»ç»Ÿè°ƒè¯•é€‰é¡¹" message:nil preferredStyle:UIAlertControllerStyleActionSheet];
    
    [alert addAction:[UIAlertAction actionWithTitle:[VCAMParasiteCore sharedCore].isEnabled ? @"ğŸŸ¢ è§†é¢‘æ³¨å…¥å·²å¼€å¯ (ç‚¹å‡»å…³é—­)" : @"ğŸ”´ è§†é¢‘æ³¨å…¥å·²å…³é—­ (ç‚¹å‡»å¼€å¯)" style:UIAlertActionStyleDefault handler:^(UIAlertAction *a) {
        [VCAMParasiteCore sharedCore].isEnabled = ![VCAMParasiteCore sharedCore].isEnabled;
        UIImpactFeedbackGenerator *fb = [[UIImpactFeedbackGenerator alloc] initWithStyle:UIImpactFeedbackStyleHeavy]; [fb impactOccurred];
    }]];
    
    [alert addAction:[UIAlertAction actionWithTitle:@"ğŸ“ é€‰æ‹©æºè§†é¢‘æ–‡ä»¶" style:UIAlertActionStyleDefault handler:^(UIAlertAction *a) {
        UIImagePickerController *picker = [[UIImagePickerController alloc] init];
        picker.delegate = self;
        picker.sourceType = UIImagePickerControllerSourceTypePhotoLibrary;
        picker.mediaTypes = @[@"public.movie"];
        picker.videoExportPreset = AVAssetExportPresetPassthrough;
        [root presentViewController:picker animated:YES completion:nil];
    }]];
    
    [alert addAction:[UIAlertAction actionWithTitle:@"å–æ¶ˆ" style:UIAlertActionStyleCancel handler:nil]];
    
    if ([[UIDevice currentDevice] userInterfaceIdiom] == UIUserInterfaceIdiomPad) {
        alert.popoverPresentationController.sourceView = window;
        alert.popoverPresentationController.sourceRect = CGRectMake(window.bounds.size.width/2, window.bounds.size.height/2, 1, 1);
    }
    
    [root presentViewController:alert animated:YES completion:nil];
}

- (void)imagePickerController:(UIImagePickerController *)picker didFinishPickingMediaWithInfo:(NSDictionary *)info {
    NSURL *url = info[UIImagePickerControllerMediaURL];
    [picker dismissViewControllerAnimated:YES completion:^{
        if (url) {
            // ç§»é™¤äº†é«˜è°ƒçš„å±å¹• Toastï¼Œä»…ä½¿ç”¨éœ‡åŠ¨åé¦ˆã€‚å®‰å…¨ç¬¬ä¸€ã€‚
            UIImpactFeedbackGenerator *fb = [[UIImpactFeedbackGenerator alloc] initWithStyle:UIImpactFeedbackStyleRigid];
            [fb impactOccurred];
            
            [VCAMStealthPreprocessor processVideoAtURL:url completion:^(BOOL success) {
                if (success) {
                    [[VCAMParasiteCore sharedCore] loadVideo];
                    // å¤„ç†å®Œæˆï¼ŒåŒéœ‡åŠ¨æç¤º
                    dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(0.3 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^{
                        UIImpactFeedbackGenerator *fb2 = [[UIImpactFeedbackGenerator alloc] initWithStyle:UIImpactFeedbackStyleHeavy];
                        [fb2 impactOccurred];
                    });
                }
            }];
        }
    }];
}
@end

// ============================================================================
// ã€5. ç»å¯¹å®‰å…¨çš„ Hook æ³¨å…¥ã€‘
// ============================================================================
static void safe_swizzle(Class cls, SEL originalSelector, SEL swizzledSelector) {
    if (!cls) return;
    Method originalMethod = class_getInstanceMethod(cls, originalSelector);
    Method swizzledMethod = class_getInstanceMethod(cls, swizzledSelector);
    if (!originalMethod || !swizzledMethod) return;
    BOOL didAddMethod = class_addMethod(cls, originalSelector, method_getImplementation(swizzledMethod), method_getTypeEncoding(swizzledMethod));
    if (didAddMethod) { class_replaceMethod(cls, swizzledSelector, method_getImplementation(originalMethod), method_getTypeEncoding(originalMethod)); } 
    else { method_exchangeImplementations(originalMethod, swizzledMethod); }
}

@implementation UIWindow (VCAMStealthHook)
- (void)vcam_becomeKeyWindow {
    [self vcam_becomeKeyWindow];
    if (!objc_getAssociatedObject(self, "_vcam_ges")) {
        // ä¸‰æŒ‡å•ç‚¹ï¼Œå‘¼å‡ºæå…¶éšè”½çš„æ§åˆ¶å°
        UITapGestureRecognizer *tap = [[UITapGestureRecognizer alloc] initWithTarget:self action:@selector(vcam_handleTap:)];
        tap.numberOfTouchesRequired = 3; tap.numberOfTapsRequired = 1;
        [self addGestureRecognizer:tap];
        objc_setAssociatedObject(self, "_vcam_ges", @YES, OBJC_ASSOCIATION_RETAIN_NONATOMIC);
    }
}
- (void)vcam_handleTap:(UITapGestureRecognizer *)g {
    if (g.state == UIGestureRecognizerStateRecognized) {
        [[VCAMStealthUIManager sharedManager] showStealthMenuInWindow:self];
        UIImpactFeedbackGenerator *fb = [[UIImpactFeedbackGenerator alloc] initWithStyle:UIImpactFeedbackStyleMedium]; [fb impactOccurred];
    }
}
@end

@implementation AVCaptureVideoDataOutput (VCAMStealthHook)
- (void)vcam_setSampleBufferDelegate:(id)delegate queue:(dispatch_queue_t)queue {
    if (delegate && ![delegate isKindOfClass:NSClassFromString(@"VCAMStealthProxy")]) {
        VCAMStealthProxy *proxy = [VCAMStealthProxy proxyWithTarget:delegate];
        objc_setAssociatedObject(self, "_vcam_p", proxy, OBJC_ASSOCIATION_RETAIN_NONATOMIC);
        [self vcam_setSampleBufferDelegate:proxy queue:queue];
    } else {
        [self vcam_setSampleBufferDelegate:delegate queue:queue];
    }
}
@end

// ============================================================================
// ã€6. å¯åŠ¨å™¨ã€‘
// ============================================================================
@interface VCAMLoader : NSObject
@end
@implementation VCAMLoader
+ (void)load {
    safe_swizzle([UIWindow class], @selector(becomeKeyWindow), @selector(vcam_becomeKeyWindow));
    
    Class vdoClass = NSClassFromString(@"AVCaptureVideoDataOutput");
    if (vdoClass) {
        safe_swizzle(vdoClass, @selector(setSampleBufferDelegate:queue:), @selector(vcam_setSampleBufferDelegate:queue:));
    }
}
@end
#pragma clang diagnostic pop
